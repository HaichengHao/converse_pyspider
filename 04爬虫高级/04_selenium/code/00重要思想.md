## 学习selenium的重要思想  
   selenium可以实现自动化控制,并且与之前的requests相比,其能够通过  
模拟浏览器得到真正的页面数据,这在当今大厂做网站动不动就只拿js渲染  
导致requests只能拿到空的标签提供了解决方案  
但是,selenium的致命缺点就是其效率极低  
  所以,学习多种爬虫方式的意义就是将它们相互融合,利用selenium可以获取  
加载后的网页源码,然后利用完整的真实的网页内容来进行接下来的爬取,当然  
是交给requests,这样虽然损失了一些效率,但是requests得到了真正的源码,
这样是折中方案,当然,后面学到的js逆向更厉害,爬虫的学习是阶段性的!!  
  还有不要觉得selenium垃圾,因为它本就不是为了爬虫而生的  
   是爬虫工程师发现了其可以作为爬虫的辅助